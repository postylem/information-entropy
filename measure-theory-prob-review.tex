%!TEX program = latexmk -xelatex
\documentclass[11pt,a4paper]{article}
\usepackage{amsmath,amsfonts,amssymb,amsthm,mathtools}
\usepackage{enumitem,booktabs}
% \usepackage{parskip}
\usepackage[margin=0.75in]{geometry}
\usepackage[no-math]{fontspec}
\setmainfont{Linux Libertine}
\usepackage[%
natbib=true,backend=biber,sorting=nymdt,%
citestyle=authoryear,bibstyle=authoryear,%
url=false,doi=false,isbn=false%
]{biblatex}
\addbibresource{/Users/j/Library/texmf/bibtex/bib/all.bib}
% import xcolor, imports and configs hyperref, defines nymdt sorting:
\input{/Users/j/Library/texmf/custom/jbib_links.tex}
\input{/Users/j/Library/texmf/custom/kast.tex}
\usepackage{cleveref} % must come after importing hyperref
\input{/Users/j/Library/texmf/custom/jformat.tex} % general formatting things
\input{/Users/j/Library/texmf/custom/information-theory-operators.tex}
\newtheorem*{theorem}{Theorem}
\theoremstyle{definition}
\newtheorem*{definition}{Def}

\newcommand\key\myuline%
\renewcommand\right\mright%
\renewcommand\left\mleft%

\begin{document}

\title{Math review for probability theory}
\author{Jacob Louis Hoover}
\date{}

%\maketitle

\section*{Basic measure theory definitions}%
\label{sec:measure_theory}
\nocite{billingsley.p:1995}

\begin{definition}
  Given a set $\Omega$, a \key{$\sigma$-algebra} (or \key{$\sigma$-field})
  $\mathcal{F}$ on $\Omega$ is a collection of subsets of $\Omega$ that
  contains $\Omega$, is closed under complementation, and is closed under
  countable unions. [It follows that $\mathcal{F}$ is closed under countable
  intersections, and contains the empty set.] Elements of a $\mathcal F$ are
  called \key{measurable sets}.
\end{definition}

\begin{definition}
  A \key{measurable space} (or \key{Borel space}) is a tuple
  $(\Omega, \mathcal{F})$, where $\Omega$ is a set and $\mathcal{F}$ a
  $\sigma$-algebra on $\Omega$.
\end{definition}

\begin{definition}
  A \key{measure} on a measurable space $(\Omega,\mathcal{F})$ is a map
  $\mu:\mathcal{F}\to \mathbb{R}\cup\{\infty\}$, where the following hold:
  \begin{itemize}[nosep]
    \item nonnegativity: $\mu(A)\in [0,\infty]$ for all $A\in \mathcal{F}$,
    \item null empty set: $\mu(\emptyset) = 0$,
    \item countable additivity (or $\sigma$-additivity):
      $\mu\left(\bigsqcup_{k=1}^\infty A_k\right)=\sum_{k=1}^{\infty}\mu(A_k)$,
      for ${\{A_k\}}_{k=1}^\infty$ a countable collection of pairwise disjoint
      sets in $\mathcal{F}$.
  \end{itemize}
  A \key{probability measure} is a measure with total measure $\mu(\Omega)=1$.
\end{definition}

\begin{definition}
  A \key{measure space} is a triple $(\Omega,\mathcal{F},\mu)$,
  where $\mu$ is a measure on measurable space $(\Omega,\mathcal{F})$.
  A \key{probability space} is measure space $(\Omega,\mathcal{F},p)$,
  where $p$ is a probability measure.
\end{definition}

\begin{definition}
  A \key{measurable function} is a map $f:\Omega \to E$,
  where $(\Omega,\mathcal{F}),(E,\mathcal{E})$ are two measurable spaces,
  such that for every
  $B\in\mathcal{E}$,
  $f^{-1}(B)\coloneqq\{\omega\in\Omega:f(\omega)\in B\}\in \mathcal{F}$.
\end{definition}

\begin{definition}
  An \key{$E$-valued random variable} is a measurable function $X:\Omega \to E$,
  where $(\Omega,\mathcal{F},p)$ is a probability space (called sample space),
  and $(E,\mathcal{E})$ is a measurable space (called observation space).
\end{definition}

\begin{definition}
  The \key{law} (or the \key{distribution}) of random variable $X$
  is the push-forward of the probability measure $p$ on $(\Omega,\mathcal{F})$
  to probability measure $p_X \coloneqq p \circ X^{-1}$ on $(E,\mathcal{E})$.
  That is, for all $B\in\mathcal{E}$, the ``probability of $X$ taking on a
  value in $B$'' is
  \begin{equation*}
    p_X(B) = p(X^{-1}(B)) =  p(\{\omega:X(\omega)\in B\}).
  \end{equation*}
  [Note: The law exists, since $X$ is a measurable function, so $X^{-1}( B )
  \in \mathcal{F}$ for all $B \in \mathcal{E}$.  Checking that $p_X(E)=1$, and
  is countably additive, we see that the law is a probability measure.]
\end{definition}

\section*{Laws of Large Numbers}%
\label{sec:LLN}
Let $X_1, X_2, \ldots, X_n$ be a sequence of random variables with identical
finite expected value $\E{X_i} = m < \infty$, for all $i$.
The laws of large numbers say that the \key{sample average}
$\bar{X}_n\coloneqq\frac1n\sum_{i=1}^n X_i$ converges to $m$.

\paragraph{The Weak LLN} (aka Khinchin's law) states that $\bar{X}_n \xrightarrow{P} m$.
That is, it \myuline{converges \emph{in probability}}:
\begin{equation*}
  \forall \, \epsilon>0, \lim_{n\to\infty}
  p_{\bar{X}_n}\left( \left|\bar{X}_n - m \right| < \epsilon \right) = 1,
  \qquad\text{that is, }
  \lim_{n\to\infty} p\left(\{\omega\in \Omega \mathrel{:}
  \left|\bar{X}_n(\omega) - m \right| < \epsilon \}\right) = 1,
\end{equation*}
The weak law says that for large $n$, there is high probability
that the sample average is arbitrarily close to $m$.  It is possible however
that $|\bar{X}_n -m| \ge \epsilon$ for an infinitely often.
The strong law says that this almost surely will not occur.

\paragraph{The Strong LLN} (aka Kolmogorov's law) states that
$\bar{X}_n\xrightarrow{a.s.} m$.
That is, it \myuline{converges \emph{almost surely}}:
\begin{equation*}
  p_{\bar{X}_n}\left( \lim_{n\to\infty}\bar{X}_n = m \right) = 1
  \qquad\text{that is, }
  p\left(\{\omega\in\Omega\mathrel{:} \lim_{n\to\infty}\bar{X}_n = m \}\right) = 1
\end{equation*}

Both the strong and weak LLN hold in the iid case, but there are other cases
where the weak holds but the strong does not
\citep[see][Example 5.4, p.71]{billingsley.p:1995}.

\printbibliography[title=References]{}
\end{document}
